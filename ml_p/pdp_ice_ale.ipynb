{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import partial_dependence\n",
    "from mlp_keras import MLP\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, specify locations\n",
    "\n",
    "folder = '../report/NO_OS/postop'\n",
    "file = '/data.csv'\n",
    "\n",
    "data = pd.read_csv(folder + file)\n",
    "\n",
    "X, y = data.iloc[:,:-1], data.iloc[:, -1]\n",
    "feature_names, target_names = data.columns[:-1].to_list(), data.columns[-1:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064748201438849"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and train the model\n",
    "\n",
    "is_model_nn = True\n",
    "\n",
    "# RF\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "\n",
    "# # NN\n",
    "# model = MLP(folder + '/data_norm.csv')\n",
    "\n",
    "# early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "# rlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss', factor=0.2, patience=5, min_lr=0.0000001)\n",
    "\n",
    "# model.train(\n",
    "#     9,\n",
    "#     3,\n",
    "#     'SGD',\n",
    "#     0.01,\n",
    "#     [early_stopping_callback, rlr_callback],\n",
    "#     dropout=0.24,\n",
    "#     save_folder=None,\n",
    "#     oversampling=False,\n",
    "#     test=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PyALE import ale\n",
    "\n",
    "df = pd.read_csv(folder + '/data_norm.csv').iloc[:, :-1]\n",
    "\n",
    "for i, f in enumerate(df.columns.to_list()):\n",
    "    plt.figure(figsize=(30, 13))\n",
    "    ale_eff = ale(\n",
    "        X=df,\n",
    "        model=model,\n",
    "        feature=[f],\n",
    "        grid_size=10,\n",
    "        include_CI=True\n",
    "    )\n",
    "\n",
    "    plt.savefig('tmp.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided model function fails when applied to the provided data set.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'RandomForestClassifier' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ivan\\mlp\\ml_p\\pdp_ice_ale.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/mlp/ml_p/pdp_ice_ale.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshap\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ivan/mlp/ml_p/pdp_ice_ale.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m shap_explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39;49mKernelExplainer(model, X_train\u001b[39m.\u001b[39;49miloc[:\u001b[39m100\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/mlp/ml_p/pdp_ice_ale.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m shap_values \u001b[39m=\u001b[39m shap_explainer\u001b[39m.\u001b[39mshap_values(X_test\u001b[39m.\u001b[39miloc[[\u001b[39m0\u001b[39m]], check_additivity\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/mlp/ml_p/pdp_ice_ale.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m shap\u001b[39m.\u001b[39msummary_plot(shap_values, X_test\u001b[39m.\u001b[39miloc[[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\.venv\\mlp\\lib\\site-packages\\shap\\explainers\\_kernel.py:96\u001b[0m, in \u001b[0;36mKernel.__init__\u001b[1;34m(self, model, data, feature_names, link, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_index_ordered \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mkeep_index_ordered\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m convert_to_data(data, keep_index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_index)\n\u001b[1;32m---> 96\u001b[0m model_null \u001b[39m=\u001b[39m match_model_to_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m     98\u001b[0m \u001b[39m# enforce our current input type limitations\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, DenseData) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, SparseData), \\\n\u001b[0;32m    100\u001b[0m        \u001b[39m\"\u001b[39m\u001b[39mShap explainer only supports the DenseData and SparseData input currently.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\.venv\\mlp\\lib\\site-packages\\shap\\utils\\_legacy.py:123\u001b[0m, in \u001b[0;36mmatch_model_to_data\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m    121\u001b[0m         out_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mf(data\u001b[39m.\u001b[39mconvert_to_df())\n\u001b[0;32m    122\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m         out_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mf(data\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    124\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProvided model function fails when applied to the provided data set.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'RandomForestClassifier' object is not callable"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "shap_explainer = shap.KernelExplainer(model, X_train.iloc[:100])\n",
    "shap_values = shap_explainer.shap_values(X_test.iloc[[0]], check_additivity=False)\n",
    "shap.summary_plot(shap_values, X_test.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def custom_scoring(est, X, y_true):\n",
    "    y_pred = np.argmax(est.predict(X), axis=1)\n",
    "    return accuracy_score(y_true.to_numpy(), y_pred)\n",
    "\n",
    "if is_model_nn:\n",
    "    results = permutation_importance(mlp.trained_model, X_train, y_train, n_repeats=10, random_state=42, scoring=custom_scoring)\n",
    "else:\n",
    "    results = permutation_importance(mlp.trained_model, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "importance = results.importances_mean\n",
    "\n",
    "for i, v in enumerate(importance):\n",
    "    print(f'Feature {i}: {v:.5f}')\n",
    "\n",
    "plt.bar(X_test.columns, importance)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "for c in y_train.unique():\n",
    "    fig, ax = plt.subplots(figsize=(22, 15))\n",
    "    pdp = PartialDependenceDisplay.from_estimator(mlp, X_train, features=[i for i in range(len(X_train.columns))], target=c, method='brute', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
